{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features+Head Starter - infer\n",
    "\n",
    "https://www.kaggle.com/code/nartaa/features-head-starter/notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モジュールの動的import(import先のファイルが更新されたときに追従する)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-26 08:35:16.071651: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-26 08:35:16.090251: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-26 08:35:16.090276: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-26 08:35:16.090771: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-26 08:35:16.093912: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version = 2.15.0\n"
     ]
    }
   ],
   "source": [
    "import os, gc, sys\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"TensorFlow version =\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 0 GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-26 08:35:18.806639: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2024-03-26 08:35:18.806684: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:129] retrieving CUDA diagnostic information for host: 77aad6f29ef1\n",
      "2024-03-26 08:35:18.806695: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:136] hostname: 77aad6f29ef1\n",
      "2024-03-26 08:35:18.806809: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:159] libcuda reported version is: 535.161.7\n",
      "2024-03-26 08:35:18.806833: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:163] kernel reported version is: 535.161.7\n",
      "2024-03-26 08:35:18.806840: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:241] kernel version seems to match DSO: 535.161.7\n"
     ]
    }
   ],
   "source": [
    "# USE MULTIPLE GPUS\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if len(gpus)<=1:\n",
    "    strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")\n",
    "    print(f'Using {len(gpus)} GPU')\n",
    "else:\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    print(f'Using {len(gpus)} GPUs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Kaggle\n",
    "# sys.path.append('/kaggle/input/d/komekami/hms-harmful-brain-activity-classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.cfg.v2 import CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixed precision enabled\n"
     ]
    }
   ],
   "source": [
    "# 自動混合精度の設定\n",
    "# https://cocoinit23.com/tensowflow-automatic-mixed-precision/\n",
    "if CFG.MIX:\n",
    "  tf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": True})\n",
    "  print(\"Mixed precision enabled\")\n",
    "else:\n",
    "  print(\"Using full precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGETS = [\"seizure_vote\", \"lpd_vote\", \"gpd_vote\", \"lrda_vote\", \"grda_vote\", \"other_vote\"]\n",
    "META = [\"spectrogram_id\", \"spectrogram_label_offset_seconds\", \"patient_id\", \"expert_consensus\"]\n",
    "\n",
    "FEATS = [['Fp1','F7','T3','T5','O1'],\n",
    "         ['Fp1','F3','C3','P3','O1'],\n",
    "         ['Fp2','F8','T4','T6','O2'],\n",
    "         ['Fp2','F4','C4','P4','O2']]\n",
    "FEATS2 = ['Fp1','T3','C3','O1','Fp2','C4','T4','O2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spec_id</th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>patient_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>853520</td>\n",
       "      <td>3911565283</td>\n",
       "      <td>6885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   spec_id      eeg_id  patient_id\n",
       "0   853520  3911565283        6885"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(os.path.join(CFG.BASE_PATH, \"test.csv\")).rename({'spectrogram_id':'spec_id'},axis=1)\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test spectrograms and eegs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 spectrogram parquets\n",
      "{853520: array([[14.91, 17.11, 11.66, ...,  0.05,  0.04,  0.05],\n",
      "       [11.13, 10.95, 10.77, ...,  0.03,  0.03,  0.02],\n",
      "       [10.88, 10.57,  8.79, ...,  0.05,  0.06,  0.06],\n",
      "       ...,\n",
      "       [ 9.61, 13.32,  9.19, ...,  0.39,  0.56,  0.29],\n",
      "       [ 8.43, 11.84, 13.64, ...,  0.45,  0.45,  0.34],\n",
      "       [12.33, 11.84,  9.42, ...,  0.46,  0.54,  0.29]], dtype=float32)}\n",
      "CPU times: user 23.2 ms, sys: 374 µs, total: 23.5 ms\n",
      "Wall time: 11.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "files = os.listdir(os.path.join(CFG.BASE_PATH, \"test_spectrograms\"))\n",
    "print(f\"There are {len(files)} spectrogram parquets\")\n",
    "\n",
    "specs = {}\n",
    "for i, v in enumerate(files):\n",
    "  tmp_df = pd.read_parquet(os.path.join(CFG.BASE_PATH, \"test_spectrograms\", v))\n",
    "  name = int(v.split('.')[0])\n",
    "\n",
    "  specs[name] = tmp_df.iloc[:, 1:].values\n",
    "\n",
    "print(specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectrogram_from_eeg(parquet_path):\n",
    "    # Load middle 50sec of EEG series\n",
    "    eeg_df = pl.read_parquet(parquet_path).to_pandas()\n",
    "    middle = (len(eeg_df) - 10_000) // 2\n",
    "    eeg_df = eeg_df.iloc[middle:middle+10_000]\n",
    "\n",
    "    # variable to hold spectrogram\n",
    "    img = np.zeros((128, 256, 4), dtype=\"float32\")\n",
    "\n",
    "    signals = []\n",
    "    for k in range(4):\n",
    "        COLS = FEATS[k]\n",
    "\n",
    "        for kk in range(4):\n",
    "            # compute pair differences\n",
    "            x = eeg_df[COLS[kk]].values - eeg_df[COLS[kk+1]].values\n",
    "\n",
    "            # fill nan\n",
    "            m = np.nanmean(x)\n",
    "            if np.isnan(x).mean() < 1:\n",
    "                x = np.nan_to_num(x, nan=m)\n",
    "            else:\n",
    "                x[:] = 0\n",
    "\n",
    "            signals.append(x)\n",
    "\n",
    "            # Raw spectrogram\n",
    "            mel_spec = librosa.feature.melspectrogram(\n",
    "                y=x,\n",
    "                sr=200,\n",
    "                hop_length=len(x)//256,\n",
    "                n_fft=1024,\n",
    "                n_mels=128,\n",
    "                fmin=0,\n",
    "                fmax=20,\n",
    "                win_length=128,\n",
    "            )\n",
    "\n",
    "            # Log transform\n",
    "            width = (mel_spec.shape[1] // 32) * 32\n",
    "            mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max).astype(np.float32)[:, :width]\n",
    "\n",
    "            # Standardize to -1 to 1\n",
    "            mel_spec_db = (mel_spec_db+40)/40\n",
    "            img[:,:,k] += mel_spec_db\n",
    "\n",
    "        # Average the 4montage differences\n",
    "        img[:,:,k] /= 4.0\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "eegs = {}\n",
    "for i, v in enumerate(test_df[\"eeg_id\"].unique()):\n",
    "    img = spectrogram_from_eeg(os.path.join(CFG.BASE_PATH, \"test_eegs\", f\"{v}.parquet\"))\n",
    "    eegs[v] = img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For kaggle\n",
    "# !pip install --no-index --find-links=/kaggle/input/tf-efficientnet-whl-files /kaggle/input/tf-efficientnet-whl-files/efficientnet-1.1.1-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.loaders.dataloader import DataLoader\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    df=test_df,\n",
    "    specs=specs,\n",
    "    eegs=eegs,\n",
    "    augment=False,\n",
    "    mode=\"test\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = '/kaggle/input/hms-efficientnet-b0/EfficientNet_v2_f0.weights.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_weights(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEfficientNet_v\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCFG\u001b[38;5;241m.\u001b[39mVER\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_f\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.weights.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 11\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mCFG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLOAD_MODELS_FROM_INFER\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/EfficientNet_v\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mCFG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVER\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_f\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.weights.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(test_loader, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     14\u001b[0m preds\u001b[38;5;241m.\u001b[39mappend(pred)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:123\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/h5py/_hl/files.py:562\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    553\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    554\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    555\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    556\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    557\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[1;32m    558\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    559\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    560\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    561\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 562\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/h5py/_hl/files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[1;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = '/kaggle/input/hms-efficientnet-b0/EfficientNet_v2_f0.weights.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "from src.models.efficientnet_b0 import EfficientNetB0\n",
    "\n",
    "model = EfficientNetB0.build_model()\n",
    "\n",
    "preds = []\n",
    "for i in range(5):\n",
    "    print(f\"Fold {i+1}\")\n",
    "    if CFG.LOAD_MODELS_FROM_INFER == \"\":\n",
    "        model.load_weights(f\"EfficientNet_v{CFG.VER}_f{i}.weights.h5\")\n",
    "    else:\n",
    "        model.load_weights(f\"{CFG.LOAD_MODELS_FROM_INFER}/EfficientNet_v{CFG.VER}_f{i}.weights.h5\")\n",
    "\n",
    "    pred = model.predict(test_loader, verbose=1)\n",
    "    preds.append(pred)\n",
    "pred = np.mean(preds, axis=0)\n",
    "\n",
    "print(\"Test preds shape\", pred.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission shape (1, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>seizure_vote</th>\n",
       "      <th>lpd_vote</th>\n",
       "      <th>gpd_vote</th>\n",
       "      <th>lrda_vote</th>\n",
       "      <th>grda_vote</th>\n",
       "      <th>other_vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3911565283</td>\n",
       "      <td>0.168616</td>\n",
       "      <td>0.029283</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.455246</td>\n",
       "      <td>0.018882</td>\n",
       "      <td>0.327716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       eeg_id  seizure_vote  lpd_vote  gpd_vote  lrda_vote  grda_vote  \\\n",
       "0  3911565283      0.168616  0.029283  0.000258   0.455246   0.018882   \n",
       "\n",
       "   other_vote  \n",
       "0    0.327716  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sub = pd.DataFrame({\"eeg_id\": test_df[\"eeg_id\"].values})\n",
    "sub[label_columns] = pred\n",
    "sub.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(\"Submission shape\", sub.shape)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "dtype: float32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check to confirm predictions sum to one\n",
    "sub.iloc[:, -6:].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
