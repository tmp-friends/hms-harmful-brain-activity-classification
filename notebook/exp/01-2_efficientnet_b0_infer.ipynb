{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EfficientNetB0 - infer\n",
    "\n",
    "Kaggle Notebookでimportする via. github\n",
    "\n",
    "- https://www.kaggle.com/code/cdeotte/efficientnetb0-starter-lb-0-43\n",
    "\n",
    "ローカルで動かす際は `$ cp output/*.h5 input/hms-efficientnet-b0/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モジュールの動的import(import先のファイルが更新されたときに追従する)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-02 23:27:40.686125: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-02 23:27:40.707095: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version = 2.12.0\n"
     ]
    }
   ],
   "source": [
    "import os, sys, gc\n",
    "\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"TensorFlow version =\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-02 23:27:41.829551: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-02 23:27:41.846695: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-02 23:27:41.846781: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-02 23:27:41.847926: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-02 23:27:41.847990: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-02 23:27:41.848031: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-02 23:27:41.888071: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-02 23:27:41.888139: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-02 23:27:41.888187: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-03-02 23:27:41.888230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 877 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "# USE MULTIPLE GPUS\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if len(gpus)<=1:\n",
    "    strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")\n",
    "    print(f'Using {len(gpus)} GPU')\n",
    "else:\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    print(f'Using {len(gpus)} GPUs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR Kaggle\n",
    "# sys.path.append('/kaggle/input/d/komekami/hms-harmful-brain-activity-classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.cfg.v1 import CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixed precision enabled\n"
     ]
    }
   ],
   "source": [
    "# 自動混合精度の設定\n",
    "# https://cocoinit23.com/tensowflow-automatic-mixed-precision/\n",
    "if CFG.MIX:\n",
    "  tf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": True})\n",
    "  print(\"Mixed precision enabled\")\n",
    "else:\n",
    "  print(\"Using full precision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label_columnsを取得\n",
    "train_df = pl.read_csv(os.path.join(CFG.BASE_PATH, \"train.csv\"))\n",
    "label_columns = train_df.columns[-6:]\n",
    "\n",
    "del train_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test shape:  (1, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>spectrogram_id</th><th>eeg_id</th><th>patient_id</th></tr><tr><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>853520</td><td>3911565283</td><td>6885</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 3)\n",
       "┌────────────────┬────────────┬────────────┐\n",
       "│ spectrogram_id ┆ eeg_id     ┆ patient_id │\n",
       "│ ---            ┆ ---        ┆ ---        │\n",
       "│ i64            ┆ i64        ┆ i64        │\n",
       "╞════════════════╪════════════╪════════════╡\n",
       "│ 853520         ┆ 3911565283 ┆ 6885       │\n",
       "└────────────────┴────────────┴────────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pl.read_csv(os.path.join(CFG.BASE_PATH, \"test.csv\"))\n",
    "\n",
    "print(\"Test shape: \", test_df.shape)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 spectrogram parquets\n",
      "{853520: array([[14.91, 17.11, 11.66, ...,  0.05,  0.04,  0.05],\n",
      "       [11.13, 10.95, 10.77, ...,  0.03,  0.03,  0.02],\n",
      "       [10.88, 10.57,  8.79, ...,  0.05,  0.06,  0.06],\n",
      "       ...,\n",
      "       [ 9.61, 13.32,  9.19, ...,  0.39,  0.56,  0.29],\n",
      "       [ 8.43, 11.84, 13.64, ...,  0.45,  0.45,  0.34],\n",
      "       [12.33, 11.84,  9.42, ...,  0.46,  0.54,  0.29]], dtype=float32)}\n",
      "CPU times: user 7.66 ms, sys: 4.67 ms, total: 12.3 ms\n",
      "Wall time: 5.48 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "files = os.listdir(CFG.SPEC_FILE_PATH_INFER)\n",
    "print(f\"There are {len(files)} spectrogram parquets\")\n",
    "\n",
    "specs = {}\n",
    "for i, v in enumerate(files):\n",
    "  tmp_df = pl.read_parquet(os.path.join(CFG.SPEC_FILE_PATH_INFER, v))\n",
    "  name = int(v.split('.')[0])\n",
    "\n",
    "  specs[name] = tmp_df.drop(\"time\").to_numpy()\n",
    "\n",
    "print(specs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test eeg\n",
    "- raw eeg dataをspectrogramへ変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt, librosa\n",
    "\n",
    "USE_WAVELET = None\n",
    "\n",
    "NAMES = [\"LL\", \"LP\", \"RP\", \"RR\"]\n",
    "FEATS = [\n",
    "    [\"Fp1\", \"F7\", \"T3\", \"T5\", \"O1\"],\n",
    "    [\"Fp1\", \"F3\", \"C3\", \"P3\", \"O1\"],\n",
    "    [\"Fp2\", \"F8\", \"T4\", \"T6\", \"O2\"],\n",
    "    [\"Fp2\", \"F4\", \"C4\", \"P4\", \"O2\"],\n",
    "]\n",
    "\n",
    "def spectrogram_from_eeg(parquet_path, display=False):\n",
    "    # Load middle 50sec of EEG series\n",
    "    eeg_df = pl.read_parquet(parquet_path).to_pandas()\n",
    "    middle = (len(eeg_df) - 10_000) // 2\n",
    "    eeg_df = eeg_df.iloc[middle:middle+10_000]\n",
    "\n",
    "    # variable to hold spectrogram\n",
    "    img = np.zeros((128, 256, 4), dtype=\"float32\")\n",
    "\n",
    "    if display:\n",
    "        plt.figure(figsize=(10, 7))\n",
    "\n",
    "    signals = []\n",
    "    for k in range(4):\n",
    "        COLS = FEATS[k]\n",
    "\n",
    "        for kk in range(4):\n",
    "            # compute pair differences\n",
    "            x = eeg_df[COLS[kk]].values - eeg_df[COLS[kk+1]].values\n",
    "\n",
    "            # fill nan\n",
    "            m = np.nanmean(x)\n",
    "            if np.isnan(x).mean() < 1:\n",
    "                x = np.nan_to_num(x, nan=m)\n",
    "            else:\n",
    "                x[:] = 0\n",
    "\n",
    "            # denoise\n",
    "            if USE_WAVELET:\n",
    "                x = denoise(x, wavelet=USE_WAVELET)\n",
    "\n",
    "            signals.append(x)\n",
    "\n",
    "            # Raw spectrogram\n",
    "            mel_spec = librosa.feature.melspectrogram(\n",
    "                y=x,\n",
    "                sr=200,\n",
    "                hop_length=len(x)//256,\n",
    "                n_fft=1024,\n",
    "                n_mels=128,\n",
    "                fmin=0,\n",
    "                fmax=20,\n",
    "                win_length=128,\n",
    "            )\n",
    "\n",
    "            # Log transform\n",
    "            width = (mel_spec.shape[1] // 32) * 32\n",
    "            mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max).astype(np.float32)[:, :width]\n",
    "\n",
    "            # Standardize to -1 to 1\n",
    "            mel_spec_db = (mel_spec_db+40)/40\n",
    "            img[:,:,k] += mel_spec_db\n",
    "\n",
    "        # Average the 4montage differences\n",
    "        img[:,:,k] /= 4.0\n",
    "\n",
    "        if display:\n",
    "            plt.subplot(2, 2, k+1)\n",
    "            plt.imshow(img[:,:,k], aspect=\"auto\", origin=\"lower\")\n",
    "            plt.title(f\"EEG {v} - Spectrogram {NAMES[k]}\")\n",
    "\n",
    "    if display:\n",
    "        plt.show()\n",
    "        plt.figure(figsize=(10,5))\n",
    "        offset = 0\n",
    "        for k in range(4):\n",
    "            if k > 0:\n",
    "                offset -= signals[3-k].min()\n",
    "                plt.plot(range(10_000), signals[k]+offset, label=NAMES[3-k])\n",
    "                offset += signals[3-k].max()\n",
    "\n",
    "        plt.legend()\n",
    "        plt.title(f\"EEG {v}  signals\")\n",
    "        plt.show()\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def denoise(x, wavelet=\"haar\", level=1):\n",
    "    coeff = pywt.wavedec(x, wavelet, mode=\"per\")\n",
    "    sigma = (1/0.6745) * maddest(coeff[-level])\n",
    "\n",
    "    uthresh = sigma * np.sqrt(2*np.log(len(x)))\n",
    "    coeff[1:] = (pywt.threshold(i, value=uthresh, mode=\"hard\") for i in coeff[1:])\n",
    "\n",
    "    ret = pywt.waverec(coeff, wavelet, mode=\"per\")\n",
    "\n",
    "    return ret\n",
    "\n",
    "def maddest(d, axis=None):\n",
    "    return np.mean(np.absolute(d - np.mean(d, axis)), axis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Numba needs NumPy 1.24 or less",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:4\u001b[0m\n",
      "Cell \u001b[0;32mIn[10], line 47\u001b[0m, in \u001b[0;36mspectrogram_from_eeg\u001b[0;34m(parquet_path, display)\u001b[0m\n\u001b[1;32m     44\u001b[0m signals\u001b[38;5;241m.\u001b[39mappend(x)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Raw spectrogram\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m mel_spec \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmelspectrogram\u001b[49m(\n\u001b[1;32m     48\u001b[0m     y\u001b[38;5;241m=\u001b[39mx,\n\u001b[1;32m     49\u001b[0m     sr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m,\n\u001b[1;32m     50\u001b[0m     hop_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(x)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m256\u001b[39m,\n\u001b[1;32m     51\u001b[0m     n_fft\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m,\n\u001b[1;32m     52\u001b[0m     n_mels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m,\n\u001b[1;32m     53\u001b[0m     fmin\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     54\u001b[0m     fmax\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[1;32m     55\u001b[0m     win_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m,\n\u001b[1;32m     56\u001b[0m )\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Log transform\u001b[39;00m\n\u001b[1;32m     59\u001b[0m width \u001b[38;5;241m=\u001b[39m (mel_spec\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m32\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m32\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lazy_loader/__init__.py:76\u001b[0m, in \u001b[0;36mattach.<locals>.__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m attr_to_modules:\n\u001b[1;32m     75\u001b[0m     submod_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_to_modules[name]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 76\u001b[0m     submod \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubmod_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(submod, name)\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;66;03m# If the attribute lives in a file (module) with the same\u001b[39;00m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;66;03m# name as the attribute, ensure that the attribute and *not*\u001b[39;00m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;66;03m# the module is accessible on the package.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:883\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/librosa/feature/spectral.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfftpack\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m util\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m filters\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParameterError\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fft_frequencies\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/lazy_loader/__init__.py:73\u001b[0m, in \u001b[0;36mattach.<locals>.__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(name):\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m submodules:\n\u001b[0;32m---> 73\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpackage_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m attr_to_modules:\n\u001b[1;32m     75\u001b[0m         submod_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_to_modules[name]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/librosa/filters.py:52\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msignal\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mndimage\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m jit\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_cache\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cache\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m util\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numba/__init__.py:55\u001b[0m\n\u001b[1;32m     50\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumba requires SciPy version 1.0 or greater. Got SciPy \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     51\u001b[0m                    \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscipy\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     52\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m---> 55\u001b[0m \u001b[43m_ensure_critical_deps\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# END DO NOT MOVE\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# ---------------------- WARNING WARNING WARNING ----------------------------\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_version\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_versions\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numba/__init__.py:42\u001b[0m, in \u001b[0;36m_ensure_critical_deps\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m numpy_version \u001b[38;5;241m>\u001b[39m (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m24\u001b[39m):\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumba needs NumPy 1.24 or less\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Numba needs NumPy 1.24 or less"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "DISPLAY = 1\n",
    "eegs = {}\n",
    "for i, v in enumerate(test_df[\"eeg_id\"].unique()):\n",
    "  img = spectrogram_from_eeg(parquet_path=os.path.join(CFG.EEG_FILE_PATH_INFER, f\"{v}.parquet\"), display=i<DISPLAY)\n",
    "\n",
    "  eegs[v] = img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: albumentations in /opt/conda/lib/python3.10/site-packages (1.4.0)\n",
      "Requirement already satisfied: numpy>=1.24.4 in /opt/conda/lib/python3.10/site-packages (from albumentations) (1.25.2)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from albumentations) (1.11.2)\n",
      "Requirement already satisfied: scikit-image>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from albumentations) (0.21.0)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from albumentations) (6.0)\n",
      "Requirement already satisfied: qudida>=0.0.4 in /opt/conda/lib/python3.10/site-packages (from albumentations) (0.0.4)\n",
      "Requirement already satisfied: opencv-python>=4.9.0 in /opt/conda/lib/python3.10/site-packages (from albumentations) (4.9.0.80)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /opt/conda/lib/python3.10/site-packages (from qudida>=0.0.4->albumentations) (1.2.2)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from qudida>=0.0.4->albumentations) (4.6.3)\n",
      "Requirement already satisfied: opencv-python-headless>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from qudida>=0.0.4->albumentations) (4.8.0.76)\n",
      "Requirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations) (3.1)\n",
      "Requirement already satisfied: pillow>=9.0.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations) (9.5.0)\n",
      "Requirement already satisfied: imageio>=2.27 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations) (2.31.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations) (2023.4.12)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations) (1.4.1)\n",
      "Requirement already satisfied: packaging>=21 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations) (21.3)\n",
      "Requirement already satisfied: lazy_loader>=0.2 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.21.0->albumentations) (0.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=21->scikit-image>=0.21.0->albumentations) (3.0.9)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install -U albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.loaders.dataloader import DataLoader\n",
    "\n",
    "test_loader = DataLoader(\n",
    "  df=test_df,\n",
    "  specs=specs,\n",
    "  eegs=eegs,\n",
    "  label_columns=label_columns,\n",
    "  batch_size=32,\n",
    "  shuffle=False,\n",
    "  mode=\"test\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "3911565283",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/kaggle/src/loaders/dataloader.py:52\u001b[0m, in \u001b[0;36mDataLoader.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"1バッチを生成\"\"\"\u001b[39;00m\n\u001b[1;32m     51\u001b[0m indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[index \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size : (index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size]\n\u001b[0;32m---> 52\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maugment:\n\u001b[1;32m     55\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_augment_batch(X)\n",
      "File \u001b[0;32m/kaggle/src/loaders/dataloader.py:119\u001b[0m, in \u001b[0;36mDataLoader._generate_data\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    115\u001b[0m     X[j, \u001b[38;5;241m14\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m14\u001b[39m, :, region] \u001b[38;5;241m=\u001b[39m img[:, \u001b[38;5;241m22\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m22\u001b[39m] \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2.0\u001b[39m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# EEG(次の4チャネル)\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# https://www.kaggle.com/code/cdeotte/how-to-make-spectrogram-from-eeg\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meegs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meeg_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    120\u001b[0m X[j, :, :, \u001b[38;5;241m4\u001b[39m:] \u001b[38;5;241m=\u001b[39m img\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 3911565283"
     ]
    }
   ],
   "source": [
    "test_loader.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR Kaggle\n",
    "# !pip install --no-index --find-links=/kaggle/input/tf-efficientnet-whl-files /kaggle/input/tf-efficientnet-whl-files/efficientnet-1.1.1-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-02 04:55:39.500227: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-03-02 04:55:39.831661: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:2254] Converted 327/1050 nodes to float16 precision using 18 cast(s) to float16 (excluding Const and Variable casts)\n",
      "2024-03-02 04:55:40.007912: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 723ms/step\n",
      "Fold 2\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Fold 3\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-02 04:55:40.292579: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-03-02 04:55:40.383900: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-03-02 04:55:40.476961: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "Fold 5\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Test preds shape (1, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-02 04:55:40.566508: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "from src.models.efficientnet_b0 import EfficientNetB0\n",
    "\n",
    "model = EfficientNetB0.build_model()\n",
    "\n",
    "preds = []\n",
    "for i in range(5):\n",
    "    print(f\"Fold {i+1}\")\n",
    "    if CFG.LOAD_MODELS_FROM_INFER == \"\":\n",
    "        model.load_weights(f\"EfficientNet_v{CFG.VER}_f{i}.h5\")\n",
    "    else:\n",
    "        model.load_weights(f\"{CFG.LOAD_MODELS_FROM_INFER}/EfficientNet_v{CFG.VER}_f{i}.h5\")\n",
    "\n",
    "    pred = model.predict(test_loader, verbose=1)\n",
    "    preds.append(pred)\n",
    "pred = np.mean(preds, axis=0)\n",
    "\n",
    "print(\"Test preds shape\", pred.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission shape (1, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>seizure_vote</th>\n",
       "      <th>lpd_vote</th>\n",
       "      <th>gpd_vote</th>\n",
       "      <th>lrda_vote</th>\n",
       "      <th>grda_vote</th>\n",
       "      <th>other_vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3911565283</td>\n",
       "      <td>0.168616</td>\n",
       "      <td>0.029283</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.455246</td>\n",
       "      <td>0.018882</td>\n",
       "      <td>0.327716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       eeg_id  seizure_vote  lpd_vote  gpd_vote  lrda_vote  grda_vote  \\\n",
       "0  3911565283      0.168616  0.029283  0.000258   0.455246   0.018882   \n",
       "\n",
       "   other_vote  \n",
       "0    0.327716  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.DataFrame({\"eeg_id\": test_df[\"eeg_id\"].values})\n",
    "sub[label_columns] = pred\n",
    "sub.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(\"Submission shape\", sub.shape)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "dtype: float32"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to confirm predictions sum to one\n",
    "sub.iloc[:, -6:].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
